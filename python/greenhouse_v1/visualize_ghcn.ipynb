{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEJNw2yQ\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine GHCN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./ghcn_hourly_data/GHCNh_*.parquet')\n",
    "print(f\"Found {len(files)} files\")\n",
    "\n",
    "columns = [\n",
    "  \"Station_ID\",\n",
    "  # \"Station_name\",\n",
    "  \"DATE\",\n",
    "  \"Latitude\",\n",
    "  \"Longitude\",\n",
    "  \"Elevation\",\n",
    "  \"temperature\",\n",
    "  \"wind_speed\",\n",
    "  \"relative_humidity\",\n",
    "  # \"wet_bulb_temperature\",\n",
    "  # \"altimeter\",\n",
    "  # \"precipitation\"\n",
    "]\n",
    "\n",
    "N = len(files)\n",
    "\n",
    "df_stations = []\n",
    "for i in range(N):\n",
    "  if i % 100 == 0:\n",
    "    print(f\"Processing file {i} of {N}\")\n",
    "  df = pd.read_parquet(files[i], engine=\"pyarrow\", columns=columns)\n",
    "\n",
    "  # Interpolate or aggregate the DATE column to get only hourly data\n",
    "  df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "  df.set_index('DATE', inplace=True)\n",
    "  df_hourly = df.resample('1h').mean(numeric_only=True).reset_index()\n",
    "  df_hourly[\"Station_ID\"] = df.iloc[0][\"Station_ID\"]\n",
    "  df_stations.append(df_hourly)\n",
    "\n",
    "df_stations = pd.concat(df_stations)\n",
    "df_stations.to_parquet(\"./output/ghcn_hourly_combined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_combined = pd.read_parquet(\"./output/ghcn_hourly_combined.parquet\")\n",
    "df_hourly_combined[df_hourly_combined[\"Station_ID\"] == \"AEI0000OMAL\"].to_csv(\"./output/tmp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./output/ghcn_hourly_combined.parquet\")\n",
    "df.rename(columns={'Latitude': 'latitude', 'Longitude': 'longitude', 'Elevation': 'elevation', 'DATE': 'ds'}, inplace=True)\n",
    "print(f\"The initial dataset has {len(df)} rows\")\n",
    "\n",
    "df = df[df[\"temperature\"].notna()]\n",
    "print(f\"After dropping stations with missing temperature values, there are {len(df)} rows\")\n",
    "\n",
    "df[\"month\"] = df[\"ds\"].dt.month\n",
    "df[\"hour\"] = df[\"ds\"].dt.hour\n",
    "\n",
    "# Drop any stations with less than 80% complete data (0.80 * 8760 = 7008)\n",
    "station_counts = df.groupby(\"Station_ID\").size().reset_index(name=\"count\")\n",
    "\n",
    "min_obs = 8760 * 0.80\n",
    "df = df[df[\"Station_ID\"].isin(station_counts[station_counts[\"count\"] >= min_obs][\"Station_ID\"])].copy()\n",
    "\n",
    "print(f\"After dropping stations with less than {min_obs} observations, there are {len(df)} rows remaining\")\n",
    "\n",
    "num_stations = df[\"Station_ID\"].nunique()\n",
    "print(f\"There are {len(df) / num_stations} measurements per station on average\")\n",
    "\n",
    "df.to_parquet(\"./output/ghcn_hourly_dropped_stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_counts = df.groupby(\"Station_ID\").size().reset_index(name=\"count\")\n",
    "station_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Month-Hour Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each location and month, calculate the average temperature at each hour.\n",
    "df_cleaned = pd.read_parquet(\"./output/ghcn_hourly_dropped_stations.parquet\")\n",
    "df_cleaned\n",
    "\n",
    "nan_count_temperature = df_cleaned[\"temperature\"].isna().sum()\n",
    "print(f\"Found {nan_count_temperature} missing temperature values\")\n",
    "\n",
    "df_avg_temp = df_cleaned.groupby(by=[\"Station_ID\", \"month\", \"hour\"]).agg({\n",
    "  \"temperature\": \"mean\",\n",
    "  \"wind_speed\": \"mean\",\n",
    "  \"relative_humidity\": \"mean\",\n",
    "  \"elevation\": \"mean\",\n",
    "  \"latitude\": \"first\",\n",
    "  \"longitude\": \"first\",\n",
    "}).reset_index()\n",
    "\n",
    "num_stations = df_avg_temp[\"Station_ID\"].nunique()\n",
    "print(f\"There are {num_stations} unique stations\")\n",
    "\n",
    "obs_per_station = len(df_avg_temp) / num_stations\n",
    "print(f\"There are {obs_per_station} observations per station on average\")\n",
    "\n",
    "# Drop any stations with less than 24*12 = 288 observations.\n",
    "station_counts = df_avg_temp.groupby(\"Station_ID\").size().reset_index(name=\"count\")\n",
    "df_avg_temp = df_avg_temp[df_avg_temp[\"Station_ID\"].isin(station_counts[station_counts[\"count\"] == 288][\"Station_ID\"])]\n",
    "\n",
    "print(f\"After dropping stations with less than 288 observations, there are {df_avg_temp['Station_ID'].nunique()} stations remaining\")\n",
    "station_counts = df_avg_temp.groupby(\"Station_ID\").size().reset_index(name=\"count\")\n",
    "\n",
    "df_avg_temp.to_parquet(\"./output/ghcn_avg_temp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an average day for each month for a sample station\n",
    "df_avg_temp = pd.read_parquet(\"./output/ghcn_avg_temp.parquet\")\n",
    "plt.rcParams['font.family'] = 'Helvetica Neue'\n",
    "# station_id = df_avg_temp[\"Station_ID\"].unique()[1000]\n",
    "station_id = \"SAM00041141\"\n",
    "print(f\"Plotting average day for station {station_id}\")\n",
    "\n",
    "df_avg_temp_station = df_avg_temp[df_avg_temp[\"Station_ID\"] == station_id].copy()\n",
    "\n",
    "# Shift hours based on the longitude\n",
    "num_hours_offset = int(df_avg_temp_station[\"longitude\"].iloc[0] / 15)\n",
    "print(f\"Shifting hours by {num_hours_offset} hours\")\n",
    "if num_hours_offset < 0:\n",
    "  num_hours_offset = 24 + num_hours_offset\n",
    "\n",
    "df_avg_temp_station[\"hour\"] = (df_avg_temp_station[\"hour\"] + num_hours_offset) % 24\n",
    "\n",
    "df_avg_temp_station = df_avg_temp_station.sort_values(by=[\"month\", \"hour\"]).reset_index()\n",
    "\n",
    "for month in df_avg_temp_station[\"month\"].unique():\n",
    "  df_month = df_avg_temp_station[df_avg_temp_station[\"month\"] == month]\n",
    "  plt.plot(df_month[\"hour\"], df_month[\"temperature\"], label=f\"Month {month}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Average Day for Station {station_id}\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Temperature (°C)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Constants\n",
    "AIR_DENSITY = 1.225  # kg/m³\n",
    "AIR_SPECIFIC_HEAT = 1005  # J/(kg·K)\n",
    "JOULE_TO_WH = 1/3600  # conversion factor\n",
    "\n",
    "\n",
    "class Params(BaseModel):\n",
    "  u_value: float          # W/m²·K\n",
    "  height: float          # m\n",
    "  infiltration_rate: float  # air changes per hour\n",
    "  thermal_mass: float    # J/m²·K\n",
    "  glazing_transmittance: float  # fraction of solar radiation transmitted\n",
    "\n",
    "\n",
    "def calculate_solar_flux(latitude, hour, day_of_year):\n",
    "  \"\"\"\n",
    "  Calculate solar flux (W/m²) for a given latitude and hour.\n",
    "  \n",
    "  Parameters:\n",
    "  latitude : float\n",
    "      Latitude in degrees (-90 to 90)\n",
    "  hour : float\n",
    "      Hour of the day (0-24)\n",
    "  day_of_year : int, optional\n",
    "      Day of the year (1-365). If None, uses current date.\n",
    "      \n",
    "  Returns:\n",
    "  float : Solar flux in W/m²\n",
    "  \"\"\"\n",
    "  # Convert to radians\n",
    "  lat_rad = np.radians(latitude)\n",
    "  \n",
    "  # Solar constant (W/m²)\n",
    "  solar_constant = 1361\n",
    "  \n",
    "  # Calculate declination angle (δ)\n",
    "  # Using Cooper's equation\n",
    "  declination = 23.45 * np.sin(np.radians(360/365 * (day_of_year - 81)))\n",
    "  declination_rad = np.radians(declination)\n",
    "  \n",
    "  # Calculate hour angle (ω)\n",
    "  # Convert hour to solar hour angle (-180 to +180 degrees)\n",
    "  hour_angle = (hour - 12) * 15\n",
    "  hour_angle_rad = np.radians(hour_angle)\n",
    "  \n",
    "  # Calculate solar elevation angle (α)\n",
    "  sin_elevation = (np.sin(lat_rad) * np.sin(declination_rad) + \n",
    "                  np.cos(lat_rad) * np.cos(declination_rad) * \n",
    "                  np.cos(hour_angle_rad))\n",
    "  elevation_angle = np.arcsin(sin_elevation)\n",
    "  \n",
    "  # If sun is below horizon, return 0\n",
    "  if sin_elevation <= 0:\n",
    "      return 0\n",
    "  \n",
    "  # Calculate atmospheric mass number\n",
    "  air_mass = 1 / sin_elevation\n",
    "  \n",
    "  # Simple atmospheric transmission model\n",
    "  # Using Meinel's formula for atmospheric transmission\n",
    "  transmission = 0.7 ** air_mass\n",
    "  \n",
    "  # Calculate actual solar flux considering Earth-Sun distance variation\n",
    "  # Using Spencer's formula for radius vector\n",
    "  B = 2 * np.pi * (day_of_year - 1) / 365\n",
    "  radius_vector = (1.000110 + 0.034221 * np.cos(B) + 0.001280 * np.sin(B) +\n",
    "                  0.000719 * np.cos(2*B) + 0.000077 * np.sin(2*B))\n",
    "  \n",
    "  # Calculate final solar flux\n",
    "  flux = (solar_constant / (radius_vector ** 2)) * sin_elevation * transmission\n",
    "  \n",
    "  return max(0, flux)\n",
    "\n",
    "\n",
    "def simulate_thermal_flux(_df: pd.DataFrame, params: Params, target_temp_daytime: float, target_temp_nighttime: float) -> Dict:\n",
    "  \"\"\"Simulate entire day of greenhouse operation.\"\"\"\n",
    "  df = _df.copy()\n",
    "\n",
    "  if \"temperature\" not in df.columns:\n",
    "    raise ValueError(\"DataFrame must contain a 'temperature' column\")\n",
    "  \n",
    "  if \"hour\" not in df.columns:\n",
    "    raise ValueError(\"DataFrame must contain a 'hour' column\")\n",
    "\n",
    "  # Calculate the temperature difference between the target temperature and the temperature outdoors.\n",
    "  is_daytime_mask = (df[\"hour\"] >= 6) & (df[\"hour\"] <= 20)\n",
    "  df.loc[is_daytime_mask, \"delta_t\"] = target_temp_daytime - df.loc[is_daytime_mask, \"temperature\"]\n",
    "  df.loc[~is_daytime_mask, \"delta_t\"] = target_temp_nighttime - df.loc[~is_daytime_mask, \"temperature\"]\n",
    "\n",
    "  # Positive conduction goes from the inside to the outside.\n",
    "  df[\"conduction_w_m2\"] = params.u_value * df[\"delta_t\"]\n",
    "\n",
    "  # Positive infiltration goes from the inside to the outside.\n",
    "  df[\"infiltration_w_m2\"] = params.height * params.infiltration_rate * AIR_DENSITY * AIR_SPECIFIC_HEAT * df[\"delta_t\"]\n",
    "\n",
    "  # Positive thermal mass goes from the inside to the outside.\n",
    "  # df[\"thermal_mass_w_m2\"] = params.thermal_mass * df[\"delta_t\"] / 24 * np.sin(2 * np.pi * df[\"hour\"] / 24) * JOULE_TO_WH\n",
    "\n",
    "  # Passive solar is always positive, and represents heating.\n",
    "  # df[\"passive_solar_w_m2\"] = calculate_solar_radiation(df, params.glazing_transmittance)\n",
    "  df[\"passive_solar_w_m2\"] = df.apply(lambda row: calculate_solar_flux(row[\"latitude\"], row[\"hour\"], row[\"day_of_year\"]), axis=1)\n",
    "\n",
    "  # This is the flux from the outside to the inside.\n",
    "  df[\"total_heat_transfer_w_m2\"] = (\n",
    "    df[\"passive_solar_w_m2\"] -\n",
    "    df[\"conduction_w_m2\"] - \n",
    "    df[\"infiltration_w_m2\"]\n",
    "  )\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_temp = pd.read_parquet(\"./output/ghcn_avg_temp.parquet\")\n",
    "print(f\"Input has {len(df_avg_temp)} rows\")\n",
    "\n",
    "# Shift all hours based on the longitude.\n",
    "df_avg_temp[\"hour_offset\"] = int(df_avg_temp[\"longitude\"].iloc[0] / 15)\n",
    "df_avg_temp.loc[df_avg_temp[\"hour_offset\"] < 0, \"hour_offset\"] = 24 + df_avg_temp.loc[df_avg_temp[\"hour_offset\"] < 0, \"hour_offset\"]\n",
    "df_avg_temp[\"hour\"] = (df_avg_temp[\"hour\"] + df_avg_temp[\"hour_offset\"]) % 24\n",
    "df_avg_temp.sort_values(by=[\"Station_ID\", \"month\", \"hour\"], inplace=True)\n",
    "df_avg_temp[\"day_of_year\"] = df_avg_temp[\"month\"] / 12 * 365 + 15\n",
    "\n",
    "print(f\"After shifting, there are {len(df_avg_temp)} rows\")\n",
    "\n",
    "station_ids = df_avg_temp[\"Station_ID\"].unique()\n",
    "print(f\"There are {len(station_ids)} unique stations\")\n",
    "\n",
    "params = Params(\n",
    "  u_value=4.0,            # W/m²·K\n",
    "  height=4.0,             # m\n",
    "  infiltration_rate=0.5,  # air changes per hour\n",
    "  thermal_mass=100000,    # J/m²·K\n",
    "  glazing_transmittance=0.8,  # fraction\n",
    ")\n",
    "target_temp_daytime = 24\n",
    "target_temp_nighttime = 18\n",
    "DAYS_PER_MONTH = 30\n",
    "SECONDS_PER_HOUR = 3600\n",
    "W_PER_KW = 1000\n",
    "\n",
    "print(\"Simulating thermal flux...\")\n",
    "df_thermal_flux = simulate_thermal_flux(df_avg_temp, params, target_temp_daytime, target_temp_nighttime)\n",
    "print(\"Done simulating thermal flux.\")\n",
    "\n",
    "df_thermal_flux[\"hourly_thermal_energy_kwh_m2\"] = df_thermal_flux[\"total_heat_transfer_w_m2\"] / W_PER_KW / SECONDS_PER_HOUR\n",
    "needs_heating_mask = df_thermal_flux[\"total_heat_transfer_w_m2\"] < 0\n",
    "needs_cooling_mask = df_thermal_flux[\"total_heat_transfer_w_m2\"] > 0\n",
    "\n",
    "df_thermal_flux[\"hourly_cooling_load_kwh_m2\"] = df_thermal_flux[\"hourly_thermal_energy_kwh_m2\"].abs() * needs_cooling_mask\n",
    "df_thermal_flux[\"hourly_heating_load_kwh_m2\"] = df_thermal_flux[\"hourly_thermal_energy_kwh_m2\"].abs() * needs_heating_mask\n",
    "\n",
    "df_thermal_flux[\"cooling_degree_hours\"] = df_thermal_flux[\"delta_t\"].abs() * (df_thermal_flux[\"delta_t\"] < 0)\n",
    "df_thermal_flux[\"heating_degree_hours\"] = df_thermal_flux[\"delta_t\"].abs() * (df_thermal_flux[\"delta_t\"] > 0)\n",
    "df_thermal_flux[\"adjusted_cooling_degree_hours\"] = df_thermal_flux[\"delta_t\"].abs() * needs_cooling_mask\n",
    "df_thermal_flux[\"adjusted_heating_degree_hours\"] = df_thermal_flux[\"delta_t\"].abs() * needs_heating_mask\n",
    "\n",
    "df_thermal_flux\n",
    "print(f\"After calculations, there are {len(df_thermal_flux)} rows\")\n",
    "df_thermal_flux.to_parquet(\"./output/ghcn_month_hour_thermal_flux.parquet\")\n",
    "\n",
    "# Add up the total costs for each month by station.\n",
    "df_total_thermal_costs = df_thermal_flux.groupby(by=[\"Station_ID\", \"month\"]).agg({\n",
    "  \"hour_offset\": \"first\",\n",
    "  \"latitude\": \"first\",\n",
    "  \"longitude\": \"first\",\n",
    "  \"relative_humidity\": \"mean\",\n",
    "  \"cooling_degree_hours\": \"sum\",\n",
    "  \"heating_degree_hours\": \"sum\",\n",
    "  \"adjusted_cooling_degree_hours\": \"sum\",\n",
    "  \"adjusted_heating_degree_hours\": \"sum\",\n",
    "  \"hourly_cooling_load_kwh_m2\": \"sum\",\n",
    "  \"hourly_heating_load_kwh_m2\": \"sum\",\n",
    "}).reset_index()\n",
    "\n",
    "# Multiply hourly values by 30 days.\n",
    "df_total_thermal_costs[\"cooling_load_kwh_m2\"] = df_total_thermal_costs[\"hourly_cooling_load_kwh_m2\"] * DAYS_PER_MONTH\n",
    "df_total_thermal_costs[\"heating_load_kwh_m2\"] = df_total_thermal_costs[\"hourly_heating_load_kwh_m2\"] * DAYS_PER_MONTH\n",
    "df_total_thermal_costs[\"cooling_degree_hours\"] = df_total_thermal_costs[\"cooling_degree_hours\"] * DAYS_PER_MONTH\n",
    "df_total_thermal_costs[\"heating_degree_hours\"] = df_total_thermal_costs[\"heating_degree_hours\"] * DAYS_PER_MONTH\n",
    "df_total_thermal_costs[\"adjusted_cooling_degree_hours\"] = df_total_thermal_costs[\"adjusted_cooling_degree_hours\"] * DAYS_PER_MONTH\n",
    "df_total_thermal_costs[\"adjusted_heating_degree_hours\"] = df_total_thermal_costs[\"adjusted_heating_degree_hours\"] * DAYS_PER_MONTH\n",
    "\n",
    "df_total_thermal_costs.drop(columns=[\"hourly_cooling_load_kwh_m2\", \"hourly_heating_load_kwh_m2\"], inplace=True)\n",
    "df_total_thermal_costs.to_parquet(\"./output/ghcn_total_thermal_costs.parquet\")\n",
    "\n",
    "df_total_thermal_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_temp = pd.read_parquet(\"./output/ghcn_avg_temp.parquet\")\n",
    "\n",
    "# Find stations iwth the highest average temperature.\n",
    "avg_temp_by_station = df_avg_temp.groupby(\"Station_ID\")[\"temperature\"].mean().reset_index()\n",
    "avg_temp_by_station.sort_values(by=\"temperature\", ascending=False, inplace=True)\n",
    "avg_temp_by_station.head(10)\n",
    "print(avg_temp_by_station.head(10))\n",
    "# station_id = \"AEI0000OMAL\"\n",
    "station_id = avg_temp_by_station.iloc[0][\"Station_ID\"]\n",
    "print(station_id)\n",
    "\n",
    "df_avg_temp_station = df_avg_temp[df_avg_temp[\"Station_ID\"] == station_id].sort_values(by=[\"month\", \"hour\"])\n",
    "df_avg_temp_station.to_csv(f\"./output/avg_temp_{station_id}.csv\")\n",
    "print(f\"Input has {len(df_avg_temp_station)} rows\")\n",
    "\n",
    "df_plot = pd.read_parquet(\"./output/ghcn_month_hour_thermal_flux.parquet\")\n",
    "df_plot = df_plot[df_plot[\"Station_ID\"] == station_id].copy()\n",
    "df_plot.to_csv(f\"./output/results_{station_id}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_hours(df_plot: pd.DataFrame, degree_hours_column: str, title: str, legend: str):\n",
    "  # Set matplotlib font:\n",
    "  plt.rcParams['font.family'] = 'Helvetica Neue'\n",
    "  fig, ax = plt.subplots(figsize=(12, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "  # Add map features\n",
    "  ax.add_feature(cfeature.COASTLINE)\n",
    "  ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "  # Set map extent with some padding\n",
    "  ax.set_extent([\n",
    "    -180, 180,\n",
    "    -65, 90\n",
    "  ])\n",
    "\n",
    "  df_plot = df_plot[[\n",
    "    \"Station_ID\", \"latitude\", \"longitude\",\n",
    "    \"heating_degree_hours\", \"cooling_degree_hours\",\n",
    "    \"adjusted_heating_degree_hours\", \"adjusted_cooling_degree_hours\",\n",
    "    \"total_cost_per_m2\",\n",
    "  ]].groupby(by=[\"Station_ID\"]).agg({\n",
    "    \"latitude\": \"first\",\n",
    "    \"longitude\": \"first\",\n",
    "    \"heating_degree_hours\": \"sum\",\n",
    "    \"cooling_degree_hours\": \"sum\",\n",
    "    \"adjusted_heating_degree_hours\": \"sum\",\n",
    "    \"adjusted_cooling_degree_hours\": \"sum\",\n",
    "    \"total_cost_per_m2\": \"sum\",\n",
    "  }).reset_index()\n",
    "\n",
    "  # # Remove any station IDs with more than the 95th percentile of heating degree hours.\n",
    "  # df_plot = df_plot[df_plot[\"heating_degree_hours\"] < df_plot[\"heating_degree_hours\"].quantile(0.95)]\n",
    "  # # Remove any station IDs with more than the 95th percentile of cooling degree hours.\n",
    "  # df_plot = df_plot[df_plot[\"cooling_degree_hours\"] < df_plot[\"cooling_degree_hours\"].quantile(0.95)]\n",
    "\n",
    "  # HEATING DEGREE HOURS\n",
    "  scatter = ax.scatter(\n",
    "    df_plot['longitude'],\n",
    "    df_plot['latitude'],\n",
    "    c=df_plot[degree_hours_column],\n",
    "    cmap='RdYlBu_r',\n",
    "    s=3\n",
    "  )\n",
    "  plt.title(f\"{title}\")\n",
    "  plt.colorbar(scatter, label=legend)\n",
    "  fig.show()\n",
    "\n",
    "\n",
    "kwh_per_mmbtu = 293.07\n",
    "electricity_price_per_kwh = 0.15\n",
    "natural_gas_price_per_kwh = 10 / kwh_per_mmbtu\n",
    "print(f\"Electricity price per kWh: ${electricity_price_per_kwh}\")\n",
    "print(f\"Natural gas price per kWh: ${natural_gas_price_per_kwh}\")\n",
    "cooling_cop = 8\n",
    "heating_cop = 0.85\n",
    "cooling_cost_per_mmbtu = electricity_price_per_kwh / cooling_cop * kwh_per_mmbtu\n",
    "print(f\"Cooling cost per mmbtu: ${cooling_cost_per_mmbtu}\")\n",
    "\n",
    "df_plot = pd.read_parquet(\"./output/ghcn_total_thermal_costs.parquet\")\n",
    "\n",
    "# Remove any station IDs with more than the 95th percentile of heating degree hours.\n",
    "df_plot = df_plot[df_plot[\"heating_degree_hours\"] < df_plot[\"heating_degree_hours\"].quantile(0.99)]\n",
    "# Remove any station IDs with more than the 95th percentile of cooling degree hours.\n",
    "df_plot = df_plot[df_plot[\"cooling_degree_hours\"] < df_plot[\"cooling_degree_hours\"].quantile(0.99)]\n",
    "\n",
    "df_plot[\"heating_cost_per_m2\"] = df_plot[\"heating_load_kwh_m2\"] * natural_gas_price_per_kwh / heating_cop\n",
    "df_plot[\"cooling_cost_per_m2\"] = df_plot[\"cooling_load_kwh_m2\"] * electricity_price_per_kwh / cooling_cop\n",
    "df_plot[\"total_cost_per_m2\"] = df_plot[\"heating_cost_per_m2\"] + df_plot[\"cooling_cost_per_m2\"]\n",
    "\n",
    "# plot_degree_hours(df_plot, \"heating_degree_hours\", \"Annual Heating-Degree Hours\", \"degree-hours (celsius)\")\n",
    "plot_degree_hours(df_plot, \"cooling_degree_hours\", \"Annual Cooling-Degree Hours (Celsius)\", \"degree-hours (celsius)\")\n",
    "# plot_degree_hours(df_plot, \"adjusted_heating_degree_hours\", \"Adjusted Annual Heating-Degree Hours (Celsius)\", \"degree-hours (celsius)\")\n",
    "# plot_degree_hours(df_plot, \"adjusted_cooling_degree_hours\", \"Adjusted Annual Cooling-Degree Hours (Celsius)\", \"degree-hours (celsius)\")\n",
    "# plot_degree_hours(df_plot, \"total_cost_per_m2\", \"Annual energy cost for climate control ($/m²)\", \"Energy cost ($/m²)\")\n",
    "\n",
    "df_monthly = df_plot[[\n",
    "  \"Station_ID\", \"month\", \"latitude\", \"longitude\",\n",
    "  \"heating_degree_hours\", \"cooling_degree_hours\",\n",
    "  \"heating_load_kwh_m2\", \"cooling_load_kwh_m2\",\n",
    "  \"total_cost_per_m2\"\n",
    "]].copy()\n",
    "\n",
    "# Round values to reduce file size.\n",
    "for col in [\"heating_degree_hours\", \"cooling_degree_hours\", \"heating_load_kwh_m2\", \"cooling_load_kwh_m2\", \"total_cost_per_m2\"]:\n",
    "  df_monthly[col] = df_monthly[col].round(2)\n",
    "df_monthly.to_csv(\"./output/ghcn_monthly_energy_costs.csv\", index=False)\n",
    "\n",
    "df_annual = df_plot.groupby(by=[\"Station_ID\"]).agg({\n",
    "  \"latitude\": \"first\",\n",
    "  \"longitude\": \"first\",\n",
    "  \"heating_degree_hours\": \"sum\",\n",
    "  \"cooling_degree_hours\": \"sum\",\n",
    "  \"heating_load_kwh_m2\": \"sum\",\n",
    "  \"cooling_load_kwh_m2\": \"sum\",\n",
    "  \"total_cost_per_m2\": \"sum\",\n",
    "}).reset_index()\n",
    "\n",
    "# Round values to reduce file size.\n",
    "for col in [\"heating_degree_hours\", \"cooling_degree_hours\", \"heating_load_kwh_m2\", \"cooling_load_kwh_m2\", \"total_cost_per_m2\"]:\n",
    "  df_annual[col] = df_annual[col].round(2)\n",
    "\n",
    "df_annual[[\n",
    "  \"Station_ID\", \"latitude\", \"longitude\",\n",
    "  \"heating_degree_hours\", \"cooling_degree_hours\",\n",
    "  \"heating_load_kwh_m2\", \"cooling_load_kwh_m2\",\n",
    "  \"total_cost_per_m2\"\n",
    "]].to_csv(\"./output/ghcn_annual_energy_costs_full.csv\", index=False)\n",
    "\n",
    "df_annual[[\"Station_ID\", \"latitude\", \"longitude\", \"heating_degree_hours\", \"cooling_degree_hours\"]].to_csv(\"./output/ghcn_annual_degree_hours.csv\", index=False)\n",
    "df_annual[[\"Station_ID\", \"latitude\", \"longitude\", \"total_cost_per_m2\"]].to_csv(\"./output/ghcn_annual_energy_costs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_lcoe_price_per_kwh = 0.04\n",
    "cooling_cost_per_mmbtu = solar_lcoe_price_per_kwh / cooling_cop * kwh_per_mmbtu\n",
    "print(f\"Cooling cost per mmbtu: ${cooling_cost_per_mmbtu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on hourly NOAA Global Historical Climatology Network (GHCN) data from 2023. Calculated using the difference between the assumed ideal greenhouse temperature of 23°C and the outdoor temperature.\n",
    "\n",
    "Based on hourly NOAA Global Historical Climatology Network (GHCN) data from 2023.\n",
    "\n",
    "Assumes an electricity price of $0.15/kWh (COP=8) and a natural gas price of $10/mmbtu (COP=0.85). Models an ideal greenhouse with a U-value of 4 W/m²·K, height of 4 m, infiltration rate of 0.5 air changes per hour, and glazing transmittance of 0.8. Passive solar heating is based on 1080 W/m² of solar radiation and hourly sun angles. Active heating and cooling is applied to maintain the greenhouse at 23°C."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-MEJNw2yQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
